{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting是概率近似正确学习的框架中，如果存在一个或一族弱分类器，那么就可以通过弱分类器提升的方法打造强分类器。\n",
    "假定最优函数为 $F^{*}(\\vec{x})$\n",
    "$$F^{*}(\\vec{x}) = \\underset{F}{\\text{arg min}}E_{(x,y)}[L(y,F(\\vec{x}))]$$\n",
    "而其中$F(\\vec{x})$时一族基函数$f_{i}(x)$的加权和\n",
    "$$F(\\vec{x})=\\sum_{i=1}^{M}\\gamma_{i}f_{i}(x)+{\\text{const}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADaBoost (adaptive boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "reference:[XGBoost:A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754)\n",
    "\n",
    "定义一个损失函数$J^{(t)}(f)$:\n",
    "$$J^{(t)}(f)=\\sum^{n}_{i=1}L(y_{i}, \\hat{y}^{(t-1)}_{i}+f_{t}(x_{i}))+\\Omega(f_{t})$$\n",
    "其中$\\hat{y}^{(t-1)}_{i}$是前$t-1$个分类器加权获得的集成分类器，$f_{t}(x_{i})$是第$t$个基本分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么以$f_{t}(x_{i})$ 作为微分量把$J^{(t)}(f)$做Taylor展开有：\n",
    "$$J^{(t)}(f)\\simeq \\sum^{n}_{i=1}[L(y_{i}, \\hat{y}^{(t-1)}_{i})+g_{i}f_{t}(x_{i})+h_{i}f^{2}_{t}(x_{i})]+\\Omega(f_{t})$$\n",
    "其中$g_{i}$是一阶导数（gradient），$h_{i}$是二阶导数（hessian）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果基本分类器其是决策树，其正则化函数$\\Omega(f_{t})=\\gamma{T}+\\frac{1}{2}\\sum^{T}_{j=1}\\omega^{2}_{j}$；\n",
    "并定义集合$I_{j}=\\{i|q(x_{i})=j\\}$\n",
    "$$\\tilde{J}^{(t)}(f)= \\sum^{n}_{i=1}[g_{i}f_{t}(x_{i})+h_{i}f^{2}_{t}(x_{i})]+\\gamma{T}+\\frac{1}{2}\\sum^{T}_{j=1}\\omega^{2}_{j}$$\n",
    "$$\\tilde{J}^{(t)}(f)= \\sum^{T}_{j=1}[(\\sum_{i\\in{I_{j}}}g_{i})f_{t}(x_{i})+\\frac{1}{2}(\\sum_{i\\in{I_{j}}}h_{i}+\\lambda)\\omega^{2}_{j}]+\\gamma{T}$$\n",
    "上式对$\\omega$求导得到最优解$$\\omega^{*}_{j}=-\\frac{\\sum_{i\\in{I_{j}}}g_{i}}{\\sum_{i\\in{I_{j}}}h_{i}+\\lambda}$$\n",
    "以及对于决策树$q$的损失函数:$$\\tilde{J}^{(t)}(q)=-\\frac{1}{2}\\sum^{T}_{j=1}\\frac{(\\sum_{i\\in{I_{j}}}g_{i})^{2}}{\\sum_{i\\in{I_{j}}}h_{i}+\\lambda}+\\gamma{T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个候选分割点，其分割信息增益为：\n",
    "$$J_{split}=\\frac{1}{2}[\\frac{(\\sum_{i\\in{I_{L}}}g_{i})^{2}}{\\sum_{i\\in{I_{L}}}h_{i}+\\lambda}+\\frac{(\\sum_{i\\in{I_{R}}}g_{i})^{2}}{\\sum_{i\\in{I_{R}}}h_{i}+\\lambda}-\\frac{(\\sum_{i\\in{I}}g_{i})^{2}}{\\sum_{i\\in{I}}h_{i}+\\lambda}]-\\gamma$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
